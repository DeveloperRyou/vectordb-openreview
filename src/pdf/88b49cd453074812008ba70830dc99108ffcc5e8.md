# DIVERSITY OF GENERATED UNLABELED DATA MAT## TERS FOR FEW-SHOT HYPOTHESIS ADAPTATION

**Anonymous authors**
Paper under double-blind review

### ABSTRACT

Generating unlabeled data has been recently shown to help address the few-shot
_hypothesis adaptation (FHA) problem, where we aim to train a classifier for the_
target domain with a few labeled target-domain data and a well-trained sourcedomain classifier (i.e., a source hypothesis), for the additional information of the
highly-compatible unlabeled data. However, the generated data of the existing
methods are extremely similar or even the same. The strong dependency among
the generated data will lead the learning to fail. In this paper, we propose a
_diversity-enhancing generative network (DEG-Net) for the FHA problem, which_
can generate diverse unlabeled data with the help of a kernel independence measure:
the Hilbert-Schmidt independence criterion (HSIC). Specifically, DEG-Net will
generate data via minimizing the HSIC value (i.e., maximizing the independence)
among the semantic features of the generated data. By DEG-Net, the generated
unlabeled data are more diverse and more effective for addressing the FHA problem.
Experimental results show that the DEG-Net outperforms existing FHA baselines
and further verifies that generating diverse data plays an important role in addressing
the FHA problem.

### 1 INTRODUCTION

Data and expert knowledge are always scarce in newly-emerging fields, thus it is very important and
challenging to study how to leverage knowledge from other similar fields to help complete tasks in
the new fields. To cope with this challenge, transfer learning methods were proposed to leverage
knowledge of source domains (e.g., data in source domains or models trained with data in source
domains) to help complete the tasks in other similar domains (a.k.a. the target domains) (Fang et al.,
2020; Jing et al., 2020; Pan & Yang, 2009; Sun et al., 2019; Teshima et al., 2020; Zamir et al., 2018).
Among many transfer learning methods, hypothesis transfer learning (HTL) methods have received a
lot of attention since it does not require access to the data in source domains, which prevents the data
leakage issue and protects the data privacy (Chi et al., 2021a; Du et al., 2017; Liang et al., 2020; Yang
et al., 2021a;b). Recently, the few-shot hypothesis adaptation (FHA) problem has been formulated to
make HTL more realistic, which is suitable to solve many problems (Liu et al., 2021; Snell et al.,
2017; Wang et al., 2020; Yang et al., 2020). In FHA, only a well-trained source-domain classifier
(i.e., source hypothesis) and few labeled target-domain data are available (Chi et al., 2021a).

Similar to HTL, FHA also aims to obtain a good target-domain classifier with the help of a source
hypothesis and few target-domain data (Chi et al., 2021a; Motiian et al., 2017). Recently, generating
_unlabeled data has been shown to be an effective strategy to address FHA (Chi et al., 2021a). The_
_target-oriented hypothesis adaptation network (TOHAN), a one-step solution to the FHA problem,_
constructed an intermediate domain to enrich the training data. The data in the intermediate domain
are highly compatible with both source domain and target domain (Balcan & Blum, 2010). By
the generated unlabeled data in the intermediate domain, TOHAN partially overcame the problems
caused by data scarce in the target domain.

However, the existing methods ignore the diversity of the generated data or the independence among
the generated data, so that the generated data are extremely similar or even the same. Lack of diversity
leads to less effective data for addressing the FHA problem. Taking the FHA task of digits datasets as
an example, we found that the data generated by TOHAN has an issue that the generator tends to
_copy target data (Figure 1(a)). To show how diversity matters in the FHA problem, we conduct the_


-----

target data generated data

(a) The copy issue of gener- (b) Classification accuracy of different amount of unlabeled data
ated data on M → _S task_ drawn from different domains on M → _S task_

Figure 1: The low-diversity issue of generated unlabeled data when solving the FHA problem. Subfigure (a)
illustrates the labeled data (left) drawn from the target domain and unlabeled data (right) generated by TOHAN
on the MNIST→SVHN (M → _S) task. It is clear that the generated data are similar to each other and seem to_
copy the original target data (middle, left). Subfigure (b) illustrates the accuracy of the data drawn from different
domains with different data volumes on the task M → _S. For the source data and target data, the accuracy of_
the model trained by them is higher as the number of the data increases. For the generated data, the growth of
data volume only helps to improve the accuracy of the model when it is small.

experiments in the digits datasets. We use a few target labeled data and the increasing unlabeled data
to train the target model. The result is shown in Figure 1(b). For the source data and target data, it is
clear that the accuracy of the model trained is higher as the number of the data increases. For the
generated data, the growth of data volume only helps to improve the accuracy of the model when it is
small (e.g., less than 45 in Figure 1(b)). However, the accuracy of the model fluctuates around 33%
regardless of the increase in the unlabeled data, when the number of data exceeds 35. This result
shows that the model trained by generate data converge faster than those trained by the source data
and target data, since the generated data have less diversity.

In this paper, to show how the diversity of unlabeled data (i.e., the independence among unlabeled
data) affects the FHA methods, we theoretically analyze the affect of the sample complexity regarding
the FHA problem (Theorem 1). In this analysis, we adopt the log-coefficient score α (Dagan et al.,
2019) to measure the dependency among unlabeled data. Our results show that we can still count
on the unlabeled data to help address the FHA problem as long as the unlabeled data are weakly
dependent (α < 0.5). Nevertheless, once α 0.5, the results in Theorem 1 may not hold, resulting
_≥_
to fail theoretically. In addition, we find that high dependency among unlabeled data usually means
that we need more unlabeled data to obtain a good target-domain classifier. From the above analysis
and Figure 1, we argue that diversity matters in addressing the FHA problem.

To this end, we propose the diversity-enhancing generative network (DEG-Net) for the FHA problem,
which is a weight-shared conditional generative method equipped with a kernel independence measure:
the Hilbert-Schmidt independence criterion (HSIC) (Gretton et al., 2005; Ma et al., 2020; Pogodin
& Latham, 2020), which is used in various situations, e.g., clustering (Song et al., 2007; Blaschko
& Gretton, 2008), independence testing (Gretton et al., 2007), and self-supervised classification
(Li et al., 2021). Although the log-coefficient score is used to analyze the affect of the sample
complexity regarding the FHA problem, its calculation requires to know the distribution regarding
the target-domain data, which is unknown in practice. Yet, HSIC can be estimate easily by the data
sample. Thus, we adopt the HSIC to calculate the dependency among generated unlabeled data.

The overview of DEG-Net is in Figure 2, showing that there are two modules in DEG-Net: the
generation module and the adaptation module. In the generation module, we train the conditional
generator with a well-trained source classifier and few target domain data. To train the generator with
both the source domain and target domain knowledge and improve the diversity of generated data
simultaneously, the generative loss of DEG-Net consists of 3 parts: the classification loss, similarity
loss and diversity loss. More specifically, DEG-Net generates data via minimizing the HSIC value
(i.e., maximizing the independence) between the semantic features of the target data and generated
data, where the semantic features are the hidden-layer outputs of the well-trained source hypothesis.
To use the generalization knowledge in the semantic features of data that is shared by different classes


-----

(Chen et al., 2020; Chi et al., 2021b; Yao et al., 2021), the generator is a weight-shared network. As
for the adaptation module, the source classifier is trained to work well over the target domain. The
adaptation module consists of a classifier and a group discriminator (Chi et al., 2021a; Motiian et al.,
2017). With the help of the group discriminator which tries to confuse the classifier to distinguish
data from different domains, the classifier is trained to classify the data over the target domain using
the generated data and few label target data.

We verify the effectiveness of DEG-Net on 8 FHA benchmark tasks (Chi et al., 2021a). Experimental
results show that DEG-Net outperforms existing FHA methods and achieves the state-of-the art
performance. Besides, due to the weight-shared mechanism, DEG-Net is much faster than previous
generative FHA methods in training. We also conduct an ablation study to verify that each component
in the DEG-Net is useful, which shows that diverse generated data can help improve the performance
when addressing the FHA problem, which lights up a novel road for the FHA problem.

### 2 PRELIMINARY AND RELATED WORKS

**Problem Setting. In this section, we formalize FHA problem mathematically. Denoting by X ⊂** R[n]
the input space and by := 1, _, K_ the output space, where K is the number of classes. The
_Y_ _{_ _· · ·_ _}_
source domain (target domain) can be defined as a joint probability distribution µ[s] on (µ[t]
_X × Y_
on ). Besides, we assume that there is a well-trained model f _[s]_ : . The f _[s]_ is trained
_X × Y_ _X →Y_
with data {x[s]i _[, y]i[s][}]i[n]=1_ [drawn][ independently and identically distributed][ (i.i.d) from][ µ][s][ with the aim of]
minimizing E[ˆ] (x,y)∼µs [ℓ(h(x), y)], where ℓ : Y × Y is a loss function to measure if two elements in
are close, and h is an element in a hypothesis set := _h :_ . Thus, f _[s]_ can be defined as
_Y_ _H_ _{_ _X →Y}_

_f_ _[s]_ := arg min Eˆ (X _s,Y s)[ℓ(h(X_ _[s]), Y_ _[s])]._ (1)
_h∈H_

_f_ _[s]_ is also called the source hypothesis in our paper. Hence, the FHA problem is defined as follow:
**Problem 1. (FHA) Given the source hypothesis f** _[s]_ _defined in Eq. (1) and the labeled dataset_
_S[t]_ := {(x[t]i[, y]i[t][)][}][m]i=1[l] _[(][m][l][ ≤]_ [7][K][, according to (][Chi et al.][,][ 2021a][;][ Park et al.][,][ 2019][)), drawn]
_i.i.d. from target domain µ[t], the FHA methods aim to train a classifier f_ _[t]_ _with f_ _[s]_ _and_
_∈H_
_S[t]_ _such that we can minimize the value of E(X_ _t,Y t)[ℓ(h(X_ _[t]), Y_ _[t])], where h ∈H._ _Namely,_
_f_ _[t]_ = arg minh∈H E(X _t,Y t)[ℓ(h(X_ _[t]), Y_ _[t])]._

**Hypothesis Transfer Learning Methods. Hypothesis transfer learning (HTL) aims to train a**
classifier with only a well-trained classifier and small labeled data or abundant unlabeled data over the
target domain (Kuzborskij & Orabona, 2013; Tommasi et al., 2010; Liang et al., 2020). In (Kuzborskij
& Orabona, 2013), they used the leave-one-out error to find the optimal transfer parameters based on
the regularized least squares with biased regularization. SHOT (Liang et al., 2020) froze the source
hypothesis and trained a domian-specific encoding module using the abundant unlabled data. Later,
neighborhood reciprocity clustering (Yang et al., 2021a) was proposed to address HTL by encouraging
reciprocal neighbors to concord in their label prediction. Different from the FHA problem, the HTL
problem does not have the limitation on the number of the target domain labeled data.

**Target-oriented Hypothesis Adaptation Network. TOHAN (Chi et al., 2021a) is a one-step solution**
for the FHA problem. It has a good performance due to using the generated unlabeled data in the
adaptation process. Motivated by the learnability in semi-supervised learning (SSL), TOHAN found
that unlabeled data in the intermediate domain, which is compatible with both the source classifier
and target classifier, can address the FHA problem for providing the additional information in the
training. Guided by this principle, the key module of TOHAN is to generate the unlabeled data drawn
from the probability distribution µ[m]:
_µ[m]_ = arg min �χ(h[s], µ) + χ(h[t], µ)� (2)
_µ_

where χ(h[s], µ) (resp. χ(h[t], µ)) measures how compatible h[s] (resp. h[t]) is with unlabeled data
distribution µ (Balcan & Blum, 2010).

### 3 THEORETICAL ANALYSIS REGARDING THE DATA DIVERSITY IN FHA

In previous works, researchers have shown that generated high-compatible data can help address the
FHA problem. However, as discussed in Section 1, the diversity of the generated data matters in


-----

addressing the FHA. Besides, the previous studies assume that the generated data is independent in
their theory, and is inconsistent with their methods. In this section, we will show how the dependency
among the generated data affects the performance of FHA methods. Similar to (Chi et al., 2021a),
our theory is also based on the theory regarding SSL (Webb & Sammut, 2010).

**Dependency Measure. Following Dagan et al. (2019), we use the log-coefficient that measures the**
dependency among observations from a random variable Z to theoretically analyze the data diversity.
**Definition 1 (Log-influence and log-coefficient (Dagan et al., 2019)). Let Z = (Z1, . . ., Zm) be a**
_random variable over (X × Y)[m]_ _and let µZ denote either its probability distribution if discrete or its_
_density if continuous. Assume that µZ > 0 on all (X × Y)[m]. For any i ̸= j ∈{1, 2, . . ., m}, define_
_the log-influence between j and i as_


_Ij,i[log][(][Z][) = 1]_ sup

4 _Z−i−j ∈_ (X × Y)[m][−][2]

_Zi, Zi[′][, Z][j]_ _[, Z]j[′]_ _[∈X × Y]_


_i[Z]j[′]_ _[Z][−][i][−][j][]]_
log _[µ][Z][[][Z][i][Z][j][Z][−][i][−][j][]][µ][Z][[][Z]_ _[′]_ (3)

_µZ[Zi[′][Z][j][Z][−][i][−][j][]][µ][Z][[][Z][i][Z]j[′]_ _[Z][−][i][−][j][]]_ _[.]_


_Then the log-coefficient of Z is defined as αlog(Z) = maxi=1,...,m_ �


_i≠_ _j_ _[I]j,i[log][(][Z][)][.]_


From Definition 1, it is clear that αlog(Z) will be zero if Zi and Zj are independent (for any i ̸= j).

**Sample Complexity Analysis for FHA. Since the generated data are unlabeled, we follow the theory**
regarding SSL to analyze how the generated unlabeled data can help address the FHA problem. More
importantly, we will analyze how the dependency among the generated data affects the performance
of FHA methods. For simplicity, we consider a binary SSL problem (i.e., K = 2).

Let f _[∗]_ : X →{0, 1} be the optimal target classifier. Let err(h) = Ex∼µtX [[][h][(][x][)][ ̸][=][ f][ ∗][(][x][)]][ be the]
true error rate of a hypothesis h ∈H over a marginal distribution µ[t]X [. In FHA, its learnability]
mainly depends on the compatibility χ : [0, 1] measuring how “compatible” h is to one
_H × X �→_
unlabeled data x. In the following, we use χ(h, µ[t]X [) =][ E][x][∼][µ][t]X [[][χ][(][h, x][)]][ to represent the expectation]

of compatibility of data from µ[t]X [on a classifier][ h][, and let][ S]X[(][m][u][)] be an observation of a random
variable X _[t,m][u]_ = (X1[t][, . . ., X]m[t] u [)][, where the distribution regarding][ X]i[t] [is][ µ]X[t] [,][ i][ = 1][, . . ., m][u][. The]
following theorem shows that, under some conditions, we can still learn a good f _[t]_ even when the
dependency among unlabeled the target data exists.

**Theorem 1. Let ˆχ(h, SX[(][m][u][)]) =** _m1u_ �x∈SX[(][m][u)] _χ(h, x) be the empirical compatibility over SX[(][m][u][)]_

_and H0 = {h ∈H : �err(h) = 0}. If f_ _[∗]_ _∈H, χ(f_ _[∗], µ[t]X_ [) = 1][ −] _[t][, and][ α][log][(][X]_ _[t,m][u][)][ <][ 1][/][2][, then]_
_mu unlabeled data and ml labeled data are sufficient to learn to error ϵ with probability 1 −_ _δ, for_


� � 1
_mu = max_ _O_

(1 − _αlog(X_ _[t,m][u]))ϵ[2][ log 2]δ_


� � VCdim(χ( ))
_H_
_,_
_O_

(1 − 2αlog(X _[t,m][u]))ϵ[2]_


��
(4)


_and_


_ml = [2]_

_ϵ_


�
_,_ (5)


�
ln(2HµtX _[,χ][(][t][ + 2][ϵ][)[2][m][l][, µ]X[t]_ []) + ln 4]

_δ_


_where χ(H) = {χh : h ∈H} is assumed to have a finite VC dimension, χh(·) = χ(h, ·), and_
_HµtX_ _[,χ][(][t][+2][ϵ][)[2][m][l][, µ]X[t]_ []][ is the expected number of splits of][ 2][m][l][ data drawn from][ µ][t]X _[using hypotheses]_
_in_ _of compatibility more than 1_ _t_ 2ϵ. In particular, with probability at least 1 _δ, we have_
_H_ _−_ _−_ _−_
_err(h[ˆ]) ≤_ _ϵ, where_ _h[ˆ] = arg maxh∈H0 ˆχ(h, SX[(][m][u][)])._

The proof of Theorem 1 is presented in Appendix A, which mainly follows the recent result in the
problem of learning from dependent data (Dagan et al., 2019).

Theorem 1 shows that when the dependency among the unlabeled data is weak (i.e., αlog(X _[t,m][u]_ ) <
1/2), we can obtain a similar result compared to classical result in the SSL theory (Balcan & Blum,
2010). Namely, if we can generate unlabeled data that are highly compatible to f _[∗], which means that_
_t is very small and thus HµtX_ _[,χ][(][t][ + 2][ϵ][)[2][m][l][, µ]X[t]_ []][ is small, thus we do not need a lot of labeled data]
to learn a good f _[t]_ (Chi et al., 2021a).

**Diversity Matters in FHA. Theorem 1 also shows that diversity of unlabeled data matters in FHA.**
There are two reasons. The first reason is that Theorem 1 might not be true if there is strong


-----

(a) Generation module (b) Adaptation module

Figure 2: Overview of the diversity-enhancing generative network (DEG-Net). It consists of generator
_G, a classifier f_ _[t]_ = ht _gt (initialize f_ _[s]_ = f _[t]) and group discriminator D. (a) In the generation_
_◦_
module, we train a generator G with freezing the classifier f _[t]_ = f _[s]. (b) In the adaptation module,_
we first pair the generated data and labeled data and use the paired data to train the discriminator D
while freezing the encoder ht. Then, we freeze the discriminator D to train the classifier f _[t]._

dependency among the unlabeled data (e.g., αlog(X _[t,m][u]_ ) > 1/2). This will directly make the
previous work lose the theoretical foundation to address the FHA problem. The second reason is that
we need more unlabeled data to reach the same error ϵ if the dependency among the unlabeled data
increases. Specifically, if αlog(X _[t,m][u]) is very close to 1/2, then mu could be a very large number._
The above reasons motivate us to take care of the dependency among the generated data. To weaken
such dependency, we propose our diversity-enhancing generative network for the FHA problem.

### 4 DIVERSITY-ENHANCING GENERATIVE NETWORK FOR FHA PROBLEM

In this section, we propose the diversity-enhancing generative network (DEG-Net) for the FHA
problem. DEG-Net has two modules: the generation module to generate diverse unlabeled data; the
adaptation module to train the classifier for the target domain.

4.1 DIVERSITY-ENHANCING GENERATION

In order to overcome the shortcomings of the current generative method for FHA problem, we come
up with solutions for both the generative architecture and the loss function. As for the generative
architecture, we propose the weight-shared conditional generative network for generating the data
with the specific category. As for the generative loss function, we design a novel loss function to
constrain the similarities and diversity of the semantic information of the generated data.

**Weight-shared Conditional Generative Network. As discussed before, for using generalized**
features which are shared among different classes to improve the quality of generated data and reduce
the time of training, the weight-shared conditional generative network is promising. Following Chi
et al. (2021a), the generator aims to generate data of specific categories from Gaussian random noise.
The encoder outputs the semantic feature and the class probability distribution of the generated data.
To achieve the aim of the generative method, we design the two-part loss functions: the classification
loss function and the similarity of semantic feature loss function.

We assume that x[gn]i = G(z[i], cn) is the generated data with a specific category, where the inputs of
generator G are the Gaussian random noise z[i] and the specific categorical information cn. Specifically,
we use the one-hot encoded label as the categorical information. The generated data x[gn]i inputs to the
well-trained source-domain classifier f _[s]_ = hs _gs, where the output of hs is the group discriminator_
_◦_
feature, which will be used in the adaptation module and the output of gs is probability feature
**_pi = (p[1]i_** _[, . . . .p]i[n][, . . ., p]i[K][)][, where][ p]i[n]_ [is the probability of the generated data belonging to the][ n][th]
class respectively. The semantic feature s[gn]i used in the similarity loss and diversity loss is the
hidden-layer output of hs (details of the hidden-layer selection can be found in Appendix C.). We
aim to update parameters of the generator to force the generated data with the categorical information


-----

**Algorithm 1 Diversity-enhancing Generative Network (DEG-Net)**
**Input: conditional generator GθG parameterized by θG, a group discriminator DθD parameterized by θD, a**
classifier fθf parameterized by θf, kernel function k, generation batch size Bn, learning rate αG, αD and αf,
total epoch Tmax, pertraining group discriminator epoch Td.
**for t = 1, 2, ....., Tmax do**

**for n = 0, 1, ..., K −** 1 do

**1: Generate random noise z and categorical information cn;**
**2: Generate data Gn(z) and then add them to Dm;**
**3: Calculate the semantic feature s and classification probability p;**
**4: Calculate the kernel matrice of semantic feature S[n]** using kernel function k;
**end**
**5: Update θG ←** _θG −_ _αG∇LGd_ (s, p) using Eq. (11);
**if t = Tmax −** _Tf then_

**for i = 1, 2, ..., Td do**

**6: Sample G1,G3 from Dm × Dm;**
**7: Sample G2,G4 from Dm × Dt;**
**8: Update θD ←** _θD −_ _αD∇LD({Gi[4]=1[}][)][ using Eq. (][12][);]_
**end**
**end**
**if t ≥** _tmax −_ _Tf then_

**9: Sample G1,G3 from Dm × Dm;**
**10: Sample G2,G4 from Dm × Dt;**
**11: Update θf ←** _θf −_ _αf_ _∇Lf_ ({Gi[4]=1[}][, x][)][ using Eq. (][13][);]
**12: Update θD ←** _θD −_ _αD∇LD({Gi[4]=1[}][)][ using Eq. (][12][);]_
**end**
**end**
**Output: a well-trained classifier fθ.**

**_x[gn]i_** belonging to the n[th] class, i.e., making pn close to 1. Specifically, we minimize the following
loss to generate the data of a specific category n:


_Lc = [1]_

_K_


_K_
�

_n=1_


1

_Bn_


_Bn_
�

_∥p[n]i_ _[−]_ [1][∥]2[2] _[,]_ (6)
_i=1_


where Bn is the batch-size of the generator.

To make the generated data closer to data in the target domain, we need to define the loss function
to measure the difference between data of two different domains. Motivated by Zheng & Zhou
(2021), DEG-Net uses the semantic features to calculate the similarities. To avoid the copy issue,
we decided to use the ℓ1 distance ∥x − **_y∥1 =_** [�]i _[ω][i][|][x][i][ −]_ _[y][i][|][, where][ ω][i][ =][ |][x][i][ −]_ _[y][i][|][2][/][ ∥][x][ −]_ **_[y][∥]2[,]_**

since it encourages larger gradients for feature dimensions with higher residual errors. Compared
to the ℓ2-norm, it is better to measure the similarity of the semantic features between the generated
images and the target images, since ℓ1 distance is more robust to outliers (Oneto et al., 2020). Thus,
the similarity loss is defined as following:


_ml_
�

_j=1_


_Ls = [1]_

_K_


_K_
�

_n=1_


1

_mlMBn_


_Bn_
�

_i=1_


��sgni _−_ **_s[t]j��1_** _[,]_ (7)


where M = maxs1,s2∈X ∥s1 − **_s2∥1 (X is compact and ∥·∥1 is continuous), ml is the number_**
of labeled data drawn from the target domain, s[t]j [and][ s]i[gn] are the semantic features of target data
and generated data, respectively. Combining Eq. (6) and Eq. (7), we obtain the loss to train the
weight-shared conditional generative network:

_LG = Lc + λLs,_ (8)

where λ 0 is a hyper-parameter between two losses. Note that optimizing Eq. (8) is corresponding
_≥_
to TOHAN’s principle Eq. (2), where Eq. (6) (resp. Eq. (7)) is corresponding to χ(h[s], µ) (resp.
_χ(h[t], µ)). To ensure that the conditional generator can generate the image with the correct class label,_
we pretrain the generator using the well-trained source model for some epochs.

**Generative Function with Diversity. As discussed above, the weak dependence of unlabeled data is**
an important condition for using generated unlabeled data to address the FHA problem. To ensure


-----

that the unlabeled data are weakly dependent among unlabeled data (i.e., to generate more diverse
unlabeled data), it is necessary to use diversity regularization to train the generator. Unfortunately,
the log-coefficient score, a dependence measure used to analyze the sample complexity, is hard
to calculate, since its calculation requires the unknown distribution regarding the target-domain
data. HSIC, a kernel independence measure can also measure the dependency of the generated data.
Different from the log-coefficient score, HSIC can be easily estimated (Gretton et al., 2005; Song
et al., 2012):

1
HSIC(� _X, Y ) =_ (9)

(N 1)[2][ Tr(][KHLH][)][,]
_−_


where K = (kij) = k(xi, xj) (L = (lij) = k(yi, yj)) is the kernel matrix (k(·, ·) is the kernel
function) and H = I − _N[1]_ **[11][⊤]** [is the centering matrix. We minimize the HSIC measure of the]

generated data’s semantic features to obtain weakly dependent data. Specifically, we use the Gaussian
kernel as the kernel function, and minimize the following loss to generate more diversity data:

_K_ _K_ �

_Ld = [1]_ � �HSIC(� **_s[gn], s[gn]) = [1]_** � 1 (10)

_K_ _K_ (Bn 1)[2][ Tr(][S][n][HS][n][H][)][,]

_n=1_ _n=1_ _−_

where S[n] = (s[n]ij[) =][ k][(][s][gn]i _[,][ s]j[gn][)][ is the kernel matrice of the semantic features of the generated data]_
with a specific class. Hence, we obtain the total loss to train the generator with diversity enhancing:

_LGd = LG + βLd,_ (11)

where β 0 is a hyper-parameter between the generative loss and diversity regularization. Note that
_≥_
the diversity regularization and the similarity loss restrict themselves.

4.2 ADAPTATION MODULE USING GENERATED DATA

Following Chi et al. (2021a), we create paired data using the labeled data in the target domain and
the generated data, and assign the group labels to the paired groups under the following rules: G1
pairs the generated data with the same class label; G2 pairs the generated data and the data in the
target domain with the same class label; G3 pairs the generated data but with different class label; G4
pairs the generated data and the data in the target domain and also with different class label. By using
adversarial learning, we train a discriminator D which could distinguish between the data in different
domains while maintaining high classification accuracy on generated data. The discriminator D
is a four-class classifier with the inputs of the above paired group data. Different from classical
adversarial domain adaptation (Ganin et al., 2016; Jiang et al., 2020), the group discriminator D
decides which of the four groups a given data pair belongs to. By freezing the encoder, we train D
with the cross-entropy loss:


�


_LD = −E[ˆ]_


� 4
�

_yGi_ _log(D(ϕ(Gi)))_
_i=1_


_,_ (12)


where E[ˆ](·) represents the empirical mean value, yGi is the group label of group Gi and ϕ(Gi) :=

[g(x1), g(x2)] is the output of the encoder with the paired data input.

Next, we will train the classifier f _[t]_ = ht _gt while freezing the group discriminator, which is_
_◦_
initialized with the same weight as that in the source classifier f _[s]_ = hs ◦ _gs. Motivated by non-_
saturating games (Goodfellow, 2016), we minimize the following loss to update f _[t]:_

_Lf = −γE[ˆ] [yG1 log (D (ϕ (G2))) −_ _yG3 log (D (ϕ (G4)))] + E[ˆ] [ℓ_ (ft (xt), ft[∗] [(][x][t][))]][,] (13)

where γ ≥ 0 is a hyper-parameter, l is the cross-entropy loss, and ft[∗] [is the optimal target model.]
Note that, the label information of generated data has as certain noise. As demonstrated in Theorem 1,
it is only necessary to use generated unlabeled data for addressing the FHA problem. Thus, we only
use labeled target data for target supervised loss in Eq. (13).

### 5 EXPERIMENTS

We compare DEG-Net with previous FHA methods on digits datasets (i.e. MNIST (M ),USPS
(U ),and SVHN (S)) and objects datasets (i.e. CIFAR-10 (CF ) and STL-10 (SL)), following (Chi


-----

Table 1: Classification accuracy standard deviation (%) on 6 digits FHA tasks. Bold value represents
_±_
the highest accuracy on each column.

Number of Target Data per Class
Tasks WA FHA Methods 1 2 3 4 5 6 7


_M →_ _U_ 69.7

_M →_ _S_ 24.1

_S →_ _U_ 64.3

_S →_ _M_ 70.2

_U →_ _M_ 82.9

_U →_ _S_ 17.3


FT 70.2±0.0 70.6±0.3 70.7±0.1 70.8±0.3 70.9±0.2 71.1±0.3 71.1±0.4
SHOT 72.6±1.9 73.6±2.0 74.1±0.6 74.6±1.2 74.9±0.7 75.4±0.3 76.1±1.5
S+FADA 74.4±1.5 83.1±0.7 83.3±1.1 85.9±0.5 86.0±1.2 87.6±2.6 89.1±1.0
T+FADA 74.2±1.8 81.6±4.0 83.4±0.8 82.0±2.3 86.2±0.7 87.2±0.8 88.2±0.6
TOHAN 76.0±1.9 83.3±0.3 84.2±0.4 86.5±1.1 87.1±1.3 88.0±0.5 89.7±0.5
DEG-Net **83.1±0.9** **86.2±0.8** **86.5±0.6** **88.7±0.9** **89.6±0.5** **91.5±0.6** **92.1±0.6**

FT 26.7±1.0 26.8±2.1 26.8±1.6 27.0±0.7 27.3±1.2 27.5±0.8 28.3±1.5
SHOT 25.7±2.2 26.9±1.2 27.9±2.6 29.1±0.4 29.1±1.4 29.6±1.7 29.8±1.5
S+FADA 25.6±1.3 27.7±0.5 27.8±0.7 28.2±1.3 28.4±1.4 29.0±1.0 29.6±1.9
T+FADA 25.3±1.0 26.3±0.8 28.9±1.0 29.1±1.3 29.2±1.3 31.9±0.4 32.4±1.8
TOHAN 26.7±0.1 **28.6±1.1** 29.5±1.4 29.6±0.4 30.5±1.2 32.1±0.2 33.2±0.8
DEG-Net **27.2±0.3** 28.5±1.3 **29.7±0.9** **30.7±0.8** **32.9±1.5** **33.7±1.8** **34.9±1.6**

FT 64.9±1.1 66.5±1.5 66.7±1.7 67.3±1.1 68.1±2.3 68.3±0.5 69.7±1.4
SHOT 74.7±0.3 75.5±1.4 75.6±1.0 75.8±0.7 77.1±2.1 77.8±1.6 79.6±0.6
S+FADA 72.2±1.4 73.6±1.4 74.7±1.4 76.2±1.3 77.2±1.7 77.8±3.0 79.7±1.9
T+FADA 71.7±0.6 74.3±1.9 74.5±0.8 75.9±2.1 77.7±1.5 76.8±1.8 79.7±1.9
TOHAN **75.8±0.9** **76.8±1.2** **79.4±0.9** 80.2±0.6 80.5±1.4 81.1±1.1 82.6±1.9
DEG-Net 75.2±0.3 76.9±1.5 78.2±1.2 **80.7±1.5** **81.7±1.7** **83.1±1.7** **84.3±2.2**

FT 70.2±0.0 70.6±0.3 70.7±0.1 70.8±0.3 70.9±0.2 71.1±0.3 71.1±0.4
SHOT 72.6±1.9 73.6±2.0 74.1±0.6 74.6±1.2 74.9±0.7 75.4±0.3 76.1±1.5
S+FADA 74.4±1.5 83.1±0.7 83.3±1.1 85.9±0.5 86.0±1.2 87.6±2.6 89.1±1.0
T+FADA 74.2±1.8 81.6±4.0 83.4±0.8 82.0±2.3 86.2±0.7 87.2±0.8 88.2±0.6
TOHAN **76.0±1.9** **83.3±0.3** 84.2±0.4 **86.5±1.1** 87.1±1.3 88.0±0.5 89.7±0.5
DEG-Net 76.2±1.3 78.2±1.3 **85.7±0.6** 85.9±0.8 **88.6±1.6** **89.5±1.2** **90.2±0.7**

FT 83.5±0.4 84.3±2.4 84.5±0.7 85.5±1.3 86.6±1.0 87.2±0.7 88.1±2.7
SHOT 83.1±0.5 85.5±0.3 85.8±0.6 86.0±0.2 86.6±0.2 86.7±0.2 87.0±0.1
S+FADA 83.2±0.2 84.0±0.3 85.0±1.2 85.6±0.5 85.7±0.6 86.2±0.6 87.2±1.1
T+FADA 82.9±0.7 83.9±0.2 84.7±0.8 85.4±0.6 85.6±0.7 86.3±0.9 86.6±0.7
TOHAN **84.0±0.5** 85.2±0.3 85.6±0.7 86.5±0.5 87.3±0.6 88.2±0.7 89.2±0.5
DEG-Net 82.2±0.7 **85.9±0.6** **86.5±1.5** **87.8±0.9** **88.9±0.9** **90.3±0.5** **91.6±1.2**

FT 23.4±1.8 23.6±2.7 23.8±1.6 24.6±1.4 24.6±1.2 24.8±0.7 25.5±1.8
SHOT **30.3±1.2** **31.6±0.4** 29.8±0.5 29.4±0.3 29.7±0.5 29.8±0.8 30.1±0.9
S+FADA 28.1±1.2 28.7±1.3 29.0±1.2 30.1±1.1 30.3±1.3 30.7±1.0 30.9±1.5
T+FADA 27.5±1.4 27.9±0.9 28.4±1.3 29.4±1.8 29.5±0.7 30.2±1.0 30.4±1.7
TOHAN 29.9±1.2 30.5±1.2 31.4±1.1 32.8±0.9 33.1±1.0 34.0±1.0 35.1±1.8
DEG-Net 29.1±1.3 30.7±1.1 **31.8±0.7** **33.0±1.6** **33.5±1.4** **35.1±1.3** **36.2±1.2**


et al., 2021a). Following the standard domain-adaptation protocols (Shu et al., 2018), we compare
DEG-Net with 4 baselines: (1) Without adaptation (WA); (2) Fine tuning (FT); (3) SHOT (Liang
et al., 2020); (4) S+FADA (Chi et al., 2021a); (5) T+FADA (Chi et al., 2021a); and (6) TOHAN (Chi
et al., 2021a). Details regarding datasets, baselines and implementation are in Appendixes B and C.

**Digits Datasets. Following Chi et al. (2021a); Motiian et al. (2017), We conduct 6 tasks of the**
adaptation among the 3 digital datasets and choose the number of target data from 1 to 7 per class.
The classifier accuracy on the target domain of our method over 6 tasks is shown in Table 1. The
results show that the performance of DEG-Net is the best on almost all the tasks. It is clear that
the accuracy of DEG-Net is lower than TOHAN when the amount of target data is too small. The
diversity regularization and the similarity loss restrict each other, to avoid the copy issue. However,
when the amount of target data is too small, the target domain information is few, so the generator is
less likely to generate similar data with the target domain. Diversity loss enhances this adversarial
effect, resulting DEG-Net degrading to TOHAN and SHOT. Another improvement of DEG-Net over
TOHAN is that the faster training process of the generator. We need 0.93s to complete the training
within each epoch in DEG-Net, while needing 1.35s in TOHAN.

**Objects Datasets. Following Chi et al. (2021a), we examine the performance of DEG-Net on 2**
object tasks and choose the number of target data as 10 per class. The classification accuracies on
object tasks are shown in Table 2. It is clear that we outperform baselines. In CF _SL, we achieve_
_→_
1.5% improvement over TOHAN. In SL _CF_, we achieve a performance accracy of 57.2%, 0.3%
_→_
improvement over S+FADA. It is clear that the effect of DEG-Net is not obvious in objective tasks. It
may be caused by the simple structure of generative networks and complexity of datasets.


-----

Table 2: Classification accuracy standard deviation (%) on 2 objects FHA tasks. Bold value
_±_
represents the highest accuracy on each row.

FHA Methods
Tasks WA FT SHOT S+FADA T+FADA TOHAN DEG-Net

_CF →_ _SL_ 70.6 71.5±1.0 71.9±0.4 72.1±0.4 71.3±0.5 72.8±0.1 **74.3±0.3**

_SL →_ _CF_ 51.8 54.3±0.5 53.9±0.2 56.9±0.5 55.8±0.8 56.6±0.3 **57.2±0.5**

Table 3: Ablation study. Classification accuracy standard deviation(%) on M _U_ . Bold value
_±_ _→_
represents the highest accuracy on each column.

Number of Target Data per Class
FHA Methods 1 2 3 4 5 6 7

TOHAN 76.0±1.9 83.3±0.3 84.2±0.4 86.5±1.1 87.1±1.3 88.0±0.5 89.7±0.5
separate generative DEG-Net 75.7±0.7 84.7±0.5 85.0±1.2 85.9±0.9 87.4±0.8 89.1±1.0 90.4 ±1.2
DEG-Net w/o diversity 87.2±1.9 **89.5±0.3** 89.2±0.4 90.2±1.1 90.3±1.3 91.1±0.5 91.2±0.5
DEG-Net **87.3±0.9** 89.2±0.8 **90.1±0.6** **90.8±0.9** **90.6±0.5** **91.5±0.6** **92.1±0.6**

**DEG-Net Generates More Diverse Data Than TOHAN. In this part, we analyze the diversity of the**
generated data by DEG-Net and TOHAN to see if our generation process can produce more diverse
data than TOHAN’s. We choose the square root of the HSIC to measure the diversity of the generated
data in the task M _S, and calculate the HSIC value among the target-domain data as a reference_
_→_
value that is 0.0013. After the calculation, the average diversity measure of DEG-Net is 0.0019, and
the average diversity measure of TOHAN is 0.0027. It is clear that DEG-Net can generate more
diverse data than TOHAN. The detailed diversity analysis can be found in Appendix D.

**Ablation Study. To show the advantage of weight-shared architecture and the diversity loss, we**
conduct two experiments: (1) The architecture of weight-shared is the same as the DEG-Net but uses
Eq. (8) to train the generator (DEG-Net without diversity). (2) The separate generative method, which
is similar to TOHAN, has K generators and use the semantic features to calculate the similarity loss
for training each generator:

1 �Bn �Ny _gn_

_LG[n]_ _s_ [= 1]Bn _∥pn −_ 1∥2[2] [+][ λ] _NyMBn_ ��si _−_ **_s[t]j��1_** _[.]_ (14)

_i=1_ _j=1_

As shown in Table 3, DEG-Net works better than both methods introduced above, and the weightshared architecture works better than the separate generative method, which reveals that both the
weight-shared architecture and the diversity loss can improve the quality of generated data and thus
achieve the higher accuracy. Specifically, compared to modified DEG-Net without the diversity loss,
the separate generative method ignores the generalization knowledge in the semantic features of data
which is shared with all the classes. Modified DEG-Net discards the diversity loss, and thus generates
the low diverse data and results in the worse performance. However, the HSIC diversity loss does
not work for all the situations. It is clear that DEG-Net achieves the similar accuracy with mo dified
DEG-Net without diversity or even worse if the amount of the labeled data is very few (i.e., m1 ≤ 2).
This phenomenon may be caused by worse data generated by diversity method. Since the diversity
loss restricting to the similarity loss, the generator is less likely to generated similar data over target
domain (i.e., the distribution of generated data is far from the target domain).

### 6 CONCLUSION

In this paper, we focus on generating more diverse unlabeled data for addressing the FHA problem.
We experimentally and theoretically prove that the diversity of generated data (i.e., the independence
among the generated data) matters in addressing the FHA problem. For addressing FHA problem,
we propose a diversity-enhancing generative network (DEG-Net), which consists of the generation
module and the adaptation module. With the weight-shared conditional generative method equipped
with a kernel independence measure: HSIC, DEG-Net can generate more diverse unlabeled data
and achieve the better performance. Experiments show that the generated data of DEG-Net are
more diverse, and thus DEG-Net achieves the state-of-the art performance when addressing the FHA
problem, which lights up a novel and theoretical-guaranteed road to the FHA problem in the future.


-----

### 7 REPRODUCIBILITY STATEMENT

We implement all methods by PyTorch 1.7.1 and Python 3.7.6, and conduct all the experiments on
two NVIDIA RTX 2080Ti GPUs. We use the standard DCGAN network (Radford et al., 2015) as the
generator network architecture. We adopt the backbone network of LeNet-5 (LeCun et al., 1998) with
batch normalization and dropout as the encoder. We employ connected layers with softmax function
as the classifier. The semantic feature in digital tasks is the output of first fully connection layer.
We adopt 3 connected layers with softmax function as the group discriminator D. We choose the
Gaussian kernel as the kernel funcion to calculate the HSIC measure. The hyper-parameter settings
details can be found in Appendix C. The details regarding to the datasets used in the paper can
be found in Appendix B. For the theoretical resultsclear explanations, we proof the Theorem 1 in
Appendix A.

### REFERENCES

Maria-Florina Balcan and Avrim Blum. A discriminative model for semi-supervised learning. Journal
_of ACM, 57(3):19:1–19:46, 2010._

Matthew Blaschko and Arthur Gretton. Learning taxonomies by dependence maximization. In
_NeurIPS, 2008._

Xiaohan Chen, Zhangyang Wang, Siyu Tang, and Krikamol Muandet. Mate: plugging in model
awareness to task embedding for meta learning. In NeurIPS, 2020.

Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Bo Han, William Cheung, and
James Kwok. Tohan: A one-step approach towards few-shot hypothesis adaptation. 2021a.

Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Bo Han, Gang Niu, Mingyuan
Zhou, and Masashi Sugiyama. Demystifying assumptions in learning to discover novel classes. In
_ICLR, 2021b._

Adam Coates, Andrew Ng, and Honglak Lee. An analysis of single-layer networks in unsupervised
feature learning. In AISTATS, 2011.

Yuval Dagan, Constantinos Daskalakis, Nishanth Dikkala, and Siddhartha Jayanti. Learning from
weakly dependent data under dobrushin’s condition. In COLT, volume 99, pp. 914–928, 2019.

Simon S Du, Jayanth Koushik, Aarti Singh, and Barnabas P´ oczos. Hypothesis transfer learning via´
transformation functions. In NeurIPS, 2017.

Tongtong Fang, Nan Lu, Gang Niu, and Masashi Sugiyama. Rethinking importance weighting for
deep learning under distribution shift. 2020.

Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc¸ois
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks.
_The journal of machine learning research, 17(1):2096–2030, 2016._

Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. _arXiv preprint_
_arXiv:1701.00160, 2016._

Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Scholkopf. Measuring statistical¨
dependence with hilbert-schmidt norms. In ALT, pp. 63–77, 2005.

Arthur Gretton, Kenji Fukumizu, Choon Teo, Le Song, Bernhard Scholkopf, and Alex Smola. A¨
kernel statistical test of independence. In NeurIPS, 2007.

Jonathan J. Hull. A database for handwritten text recognition research. IEEE Transactions on pattern
_analysis and machine intelligence, 16(5):550–554, 1994._

Pin Jiang, Aming Wu, Yahong Han, Yunfeng Shao, Meiyu Qi, and Bingshuai Li. Bidirectional
adversarial training for semi-supervised domain adaptation. In IJCAI, 2020.


-----

Yongcheng Jing, Xiao Liu, Yukang Ding, Xinchao Wang, Errui Ding, Mingli Song, and Shilei Wen.
Dynamic instance normalization for arbitrary style transfer. In AAAI, 2020.

Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.

Ilja Kuzborskij and Francesco Orabona. Stability and hypothesis transfer learning. In ICML, 2013.

Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to´
document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.

Yazhe Li, Roman Pogodin, Danica J Sutherland, and Arthur Gretton. Self-supervised learning with
kernel dependence maximization. 2021.

Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source
hypothesis transfer for unsupervised domain adaptation. In ICML, 2020.

Lu Liu, William Hamilton, Guodong Long, Jing Jiang, and Hugo Larochelle. A universal representation transformer layer for few-shot image classification. In ICLR, 2021.

Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial
domain adaptation. In NeurIPS, 2018.

Wan-Duo Kurt Ma, JP Lewis, and W Bastiaan Kleijn. The HSIC bottleneck: Deep learning without
back-propagation. In AAAI, 2020.

Saeid Motiian, Quinn Jones, Seyed Iranmanesh, and Gianfranco Doretto. Few-shot adversarial
domain adaptation. 2017.

Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading
digits in natural images with unsupervised feature learning. In NeurIPS, 2011.

Luca Oneto, Michele Donini, Giulia Luise, Carlo Ciliberto, Andreas Maurer, and Massimiliano
Pontil. Exploiting mmd and sinkhorn divergences for fair and transferable representation learning.
In NeurIPS, 2020.

Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on Knowledge
_and Data Engineering, 22(10):1345–1359, 2009._

Seonwook Park, Shalini De Mello, Pavlo Molchanov, Umar Iqbal, Otmar Hilliges, and Jan Kautz.
Few-shot adaptive gaze estimation. In ICCV, 2019.

Roman Pogodin and Peter Latham. Kernelized information bottleneck leads to biologically plausible
3-factor hebbian learning in deep networks. In NeurIPS, 2020.

Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.

Connor Shorten and Taghi M Khoshgoftaar. A survey on image data augmentation for deep learning.
_Journal of big data, 2019._

Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A dirt-t approach to unsupervised domain
adaptation. In ICLR, 2018.

Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. In
_NeurIPS, 2017._

Le Song, Alex Smola, Arthur Gretton, and Karsten M Borgwardt. A dependence maximization view
of clustering. In ICML, 2007.

Le Song, Alex Smola, Arthur Gretton, Justin Bedo, and Karsten Borgwardt. Feature selection via
dependence maximization. Journal of Machine Learning Research, 13(5), 2012.

Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele. Meta-transfer learning for few-shot
learning. In CVPR, 2019.


-----

Takeshi Teshima, Issei Sato, and Masashi Sugiyama. Few-shot domain adaptation by causal mechanism transfer. In NeurIPS, 2020.

Tatiana Tommasi, Francesco Orabona, and Barbara Caputo. Safety in numbers: Learning categories
from few examples with multi model knowledge transfer. In CVPR, 2010.

Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. Generalizing from a few examples:
A survey on few-shot learning. ACM computing surveys (csur), 53(3):1–34, 2020.

Geoffrey I Webb and Claude Sammut. Encyclopedia of machine learning. Springer, 2010.

Shiqi Yang, Joost van de Weijer, Luis Herranz, Shangling Jui, et al. Exploiting the intrinsic neighborhood structure for source-free domain adaptation. 2021a.

Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized
source-free domain adaptation. In ICCV, 2021b.

Shuo Yang, Lu Liu, and Min Xu. Free lunch for few-shot learning: Distribution calibration. In ICLR,
2020.

Huaxiu Yao, Long-Kai Huang, Linjun Zhang, Ying Wei, Li Tian, James Zou, Junzhou Huang, et al.
Improving generalization in meta-learning via task augmentation. In ICML, 2021.

Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, and Silvio Savarese.
Taskonomy: Disentangling task transfer learning. In CVPR, 2018.

Huangjie Zheng and Mingyuan Zhou. Exploiting chain rule and bayes’ theorem to compare probability
distributions. 2021.


-----

### A PROOF OF THEOREM 1

Before proving the Theorem 1, we first introduce a McDiarmid-like inequality under the logcoefficient of a random vector Z.

**Lemma 1 (McDiarmid-like Inequality under the Log-coefficient of Z). Let µ[(][m][)]** _be a distribution_
_defined over Z_ _[m], and Z = (Z1, . . ., Zm) ∼_ _µ[(][m][)]_ _be a random vector, and g : Z_ _[m]_ _→_ R with the
_following bounded differences property with parameters λ1, . . ., λm > 0:_


_∀Zi, Zj : |g(Zi) −_ _g(Zj)| ≤_


_m_
�

1Zi≠ _Zj_ _λi,_ (15)
_i=1_


_where Z_ _[m]_ = (X × Y)[m]. If αlog(Z) < 1, then, for all t > 0,

�
Pr[|g(Z) − E[g(Z)]| ≥ _t] ≤_ 2 exp _−_ [(1][ −] _[α][log][(][Z][))][t][2]_

2 [�]i[m]=1 _[λ]i[2]_


�
_._ (16)


_Proof. Based on Definition 2.2 and Lemma 5.2 in (Dagan et al., 2019), we know that µ[(][m][)]_ satisfies
Dobrushin’s condition with a coefficient α < 1. Thus, based on Theorem 2.3 in (Dagan et al., 2019),
we have


�
Pr[|g(Z) − E[g(Z)]| ≥ _t] ≤_ 2 exp _−_ [(1][ −] _[α][)][t][2]_

2 [�]i[m]=1 _[λ]i[2]_

Since, α ≤ _αlog(Z), we prove this lemma._


�
_._ (17)


Then, we introduce a recent result regarding bounding the expected suprema of a empirical process
using the corresponding Gaussian complexity.

**Theorem 2 ((Dagan et al., 2019)). Let Z be a random vector over some domain Z** _[m]_ _and let G be a_
_class of functions from Z to R. If αlog(Z) < 1/2, then_


_m_
�

_g(si)_
_i=1_


_CGZ(G)_

_,_ (18)

_≤_ �1 − 2αlog(Z)


_m_
�

_g(si) −_ E
_S_
_i=1_


�
1

_m_


��


E
_S∼Z_ [sup]g∈G


�
1

_m_


_where C > 0 is a universal constant, and S = (s1, . . ., sm) is a sample of Z._

Note that, the above result is very general, it does not assume that the m marginals of the distribution
of Z are identical. Based on the above theorem and lemma, we can prove the following lemma.

**Lemma 2. Let Z be a random vector over some domain Z** _[m]_ _and let G be a class of functions from_
_Z to R. If αlog(Z) < 1/2, and there exists L > 0 such that for any g ∈G and Zi, |g(Zi)| ≤_ _L, then,_
_for any t > 0,_


�


_m_
� _CGZ(G)_

_i=1_ _g(si)������_ _≥_ �1 − 2αlog(Z) + t


�


(1−αlog(Z))mt[2]
_e[−]_ _C[′]_ _L[2]_ (19)
_≤_


�
1

_m_


Pr
_S∼Z_


sup
_g∈G_


1

_m_

�����


_m_
�

_g(si) −_ E
_S_
_i=1_


_for some universal constants C, C_ _[′]_ _> 0._

_Proof. We first consider proving the non-absolute-value version. Let_


_m_
�

_g(si)_
_i=1_


_m_
�

_g(si) −_ E
_S_
_i=1_


�
1

_m_


��


_M_ (S) = sup
_g∈G_


�
1

_m_


_._ (20)


For any S ∼ **_Z and S[′]_** _∼_ **_Z, we have that |M_** (S) − _M_ (S[′])| ≤ [�]i[m]=1 [2][L][1][s]i[̸][=][s][′]i _[/m][. According to]_
Lemma 1, we have


�
Pr
_S∼Z_ [[][M] [(][S][)][ −] [E][[][M] [(][S][)]][ ≥] _[t][]][ ≤]_ [exp] _−_ [(1][ −] _[α]C[log][′]L[(][Z][2]_ [))][mt][2]


�
(21)


-----

for some universal constant C _[′]_ _> 0. Then, combining E[M_ (S)] (based on Theorem 2), we have


�


�
1

_m_


�
1

_m_


��


�


_SPr∼Z_ �supg∈G � _m1_ �i=1m _g(si) −_ ES � _m1_ �i=1m _g(si)��_ _≥_ �1C −G2Zα(logG)(Z) + t� _≤_ _e[−]_ (1−αlog(C[′] _LZ[2]))mt[2]_ _._

(22)

For the opposite inequality, _M_ (S) part, following (Dagan et al., 2019), we can apply the same
_−_
arguments on −G. Note that G(−G) = G(G), which concludes the bound.

The above lemma is a slightly general version of Theorem 6.7 in (Dagan et al., 2019) by considering
the influence of αlog(Z). Based on Lemma 2, we can prove the Theorem 1 below.

**Theorem 1. Let ˆχ(h, SX[(][m][u][)]) =** _m1u_ �x∈SX[(][m][u)] _χ(h, x) be the empirical compatibility over SX[(][m][u][)]_

_and H0 = {h ∈H : �err(h) = 0}. If f_ _[∗]_ _∈H, χ(f_ _[∗], µ[t]X_ [) = 1][ −] _[t][, and][ α][log][(][X]_ _[t,m][u][)][ <][ 1][/][2][, then]_
_mu unlabeled data and ml labeled data are sufficient to learn to error ϵ with probability 1 −_ _δ, for_

� � 1 � � VCdim(χ( )) ��

_H_

_mu = max_ _O_ _, O_ (4)

(1 − _αlog(X_ _[t,m][u]))ϵ[2][ log 2]δ_ (1 − 2αlog(X _[t,m][u]))ϵ[2]_


_and_


_ml = [2]_

_ϵ_


�
_,_ (5)


�
ln(2HµtX _[,χ][(][t][ + 2][ϵ][)[2][m][l][, µ]X[t]_ []) + ln 4]

_δ_


_where χ(H) = {χh : h ∈H} is assumed to have a finite VC dimension, χh(·) = χ(h, ·), and_
_HµtX_ _[,χ][(][t][+2][ϵ][)[2][m][l][, µ]X[t]_ []][ is the expected number of splits of][ 2][m][l][ data drawn from][ µ][t]X _[using hypotheses]_
_in_ _of compatibility more than 1_ _t_ 2ϵ. In particular, with probability at least 1 _δ, we have_
_H_ _−_ _−_ _−_
_err(h[ˆ]) ≤_ _ϵ, where_ _h[ˆ] = arg maxh∈H0 ˆχ(h, SX[(][m][u][)])._

_Proof. Let S be the set of mu unlabeled data. Based on the relation between VC dimension and the_
Gaussian complexity, Lemma 2 gives that, with probability at least 1 − 2[δ] [, we have]

_|Prx∼S¯[χh(x) = 1] −_ Prx∼µtX [[][χ][h][(][x][) = 1]][| ≤] _[ϵ]_ for all χh ∈ _χ(H),_

where _S[¯] denotes the uniform distribution over S. Since χh(x) = χ(h, x), this implies that we have_

_χ(h, D)_ _χˆ(h, S)_ _ϵ_ for all h _._
_|_ _−_ _| ≤_ _∈H_

Therefore, the set of hypotheses with ˆχ(h, S) ≥ 1 − _t −_ _ϵ is contained in HµtX_ _[,χ][(][t][ + 2][ϵ][)][.]_

The bound on the number of labeled data now follows directly from known concentration results
using the expected number of partitions instead of the maximum in the standard VC-dimension
bounds. This bound ensures that with probability 1 − 2[δ] [, none of the functions][ h][ ∈H][µ][t]X _[,χ][(][t][ + 2][ϵ][)]_

with err(h) _ϵ have_ _err(h) = 0._
_≥_ �

The above two arguments together imply that with probability 1 _δ, all h_ with _err(h) = 0 and_
_−_ _∈H_ �
_χˆ(h, S) ≥_ 1−t−ϵ have err(h) ≥ _ϵ, and furthermore f_ _[∗]_ has ˆχ(f _[∗], S) ≥_ 1−t−ϵ. This in turn implies
that with probability at least 1 − _δ, we have err(h[ˆ]) ≤_ _ϵ, where_ _h[ˆ] = arg maxh∈H0 ˆχ(h, S)._

### B DATASETS

**Digits.** Following TOHAN(Chi et al., 2021a), we conduct 6 adaptation experiments on digits
datasets: M _U_, M _S, S_ _U_,S _M_, U _M and U_ _S. MNIST (M_ ) (LeCun et al.,
_→_ _→_ _→_ _→_ _→_ _→_

1998) is the handwritten digits dataset, which have been size-normalized adn centered in 28 28
_×_
pixels. SVHN (S) (Netzer et al., 2011) is the real-world image digits dataset, of which images are
32 32 pixels with 3 channels. USPS (U ) (Hull, 1994) data are 16×16 grayscale pixels. The SVHN
_×_
and USPS images are resized to 28 28 grayscale pixels in the adaptation task (Chi et al., 2021a).
_×_

**Objects.** Following (Sun et al., 2019), we compared DEG-Net and benchmark on CIFAR-10 and
STL-10. The CIFAR-10 (Krizhevsky et al., 2009) dataset contains 60, 000 32 32 color images in
_×_
10 categories, while the STL-10 (Coates et al., 2011) dataset is inspired by the CIFAR-10 dataset
with some modifications. However, these two datasets only contain nine overlapping classes. We
removed the non-overlapping classes (“frog” and “monkey”) (Shu et al., 2018).


-----

### C DETAILS REGARDING EXPERIMENTS

**Baselines. We follow the standard domain-adaptation protocols (Shu et al., 2018) and compare DEG-**
Net with 4 baseline: (1) Without adaptation (WA): to classify target domain with the well-trained
source domain calssifier. (2) Fine tuning (FT): to train the last connected layer of the classifier with
few accessible labeled data. (3) SHOT: an HTL mehtod, where we modify it to use both the labeled
target data and unlabeled target data (Liang et al., 2020). (4) S+FADA:to generate unlabeled data
using the loss Lc with the well-trained source clasifier and apply them into DANN (Ganin et al.,
2016). (5) T+FADA:to generate unlabeled data using the loss Ls with the few labeled target data and
apply them into DANN. (6) TOHAN: a novel FHA method, which generate the specific category
unlabeled data separately (Chi et al., 2021a).

**Implementation Details. We implement all methods by PyTorch 1.7.1 and Python 3.7.6, and conduct**
all the experiments on NVIDIA RTX 2080Ti GPUs. Due to the limitation of the accessible computing
resources, we can not choose more complex networks as the backbone of the generator.

Our conditional generator G uses the standard DCGAN network (Radford et al., 2015). We adopt the
backbone network of LeNet-5 with batch normalization and dropout to extarct the group discriminator
feature. We employ connected layers with softmax function as the classifier to obtain the probability.
The semantic feature in digital tasks is the output of first fully connection layer. We adopt 3 connected
layers with softmax function as the group discriminator D.

**Hyper-parameter Settings. Following the common protocol of domain adaptation (Shu et al., 2018),**
we set fixed hyper-parameters for the different datasets. We pretrain the conditional generator for 300
epochs and pretrain the group discriminator for 100 epochs. The training step of the classifier (i.e. the
adaptation module) are set 50. As for the generator and the group discriminator, the learding rate of
adam optimizer is set to 1 10[−][3]. As for the classifier, the learding rate of adam optimizer is set to
_×_
1 10[−][2]. The tradeoff parameter λ in Eq. (8) is set to 0.9 and the tradeoff parameter β in Eq. (11) is
_×_
set to 0.1. Following (Long et al., 2018) the radeoff parameter γ in Eq. (13) is set to 1+exp(2−10 ˙q) _[−]_ [1][.]

### D ADDITIONAL ANALYSIS

**Augmentation Techniques on the FHA Problem** In this section, we compare the accuracy of the
target classifier trained by TOHAN and that of TOHAN with the basic geometric data augmentation
for FHA problem over the digit tasks. The geometric data augmentation technique has been widelyexplored to diversify the image data (Shorten & Khoshgoftaar, 2019). In our experiment, we randomly
choose one or more the following augmentation technique: resizing, shifting, cropping and slight
rotations (1 and 20 and -1 to -20) fot the generated data in TOHAN. The classifier accuracy on the
target domain of our method over 4 experiments and the average accuracy is shown in Table 4.

It is clear that the performance of the augmentation techniques is worse than our method in general.
It may be caused by the fact that the generated image are similar and even the same as the few target
data. The diversity of is still low with data augmentation. The accuracy of the augmentation is
basically the same as TOHAN’s. The improvement brought by the augmentation is more obvious
while the number of the target data is increasing.

**Diversity Analysis of DEG-Net** In this section, we compare the diversity of generated data of
DEG-Net with that of TOHAN and target data. Because of the difficulty of calculating log-influence,
we use the HSIC to measure the diversity of data. Considering that the generated batch in the training
process is 32, we calculate the HSIC measure with the 32 sample data. Table 5 shows the diversity of
the different data. It is clear that the diversity loss in DEG-Net works well to make the generated data
data more diverse.

**Data Efficiency Analysis of DEG-Net** In this section, we conduct the experiments in the taskS
_M_ _S and M_ _U to analyze the efficiency of the generated data. Following the architecture of_
_→_ _→_
the DEG-Net, we use the Eq. (11) to train the conditional generator and obtain the following loss to


-----

Table 4: Classification accuracy standard deviation (%) on digits FHA tasks of the data augmentation.
_±_
Bold value represents the highest average accuracy on each column.

Number of Target Data per Class
Method Tasks

1 2 3 4 5 6 7


_M →_ _U_ 77.1±0.4 83.5±0.6 84.0±0.7 86.7±1.1 87.5±0.6 88.1±1.4 89.4±1.1
_M →_ _S_ 26.7±1.0 27.8±1.6 29.7±1.3 29.4±0.7 30.3±1.2 32.4±0.8 33.5±1.5

TOHAN with augmentation _S →_ _M_ 76.4±0.5 78.6±0.3 82.7±0.1 86.5±0.3 87.9±0.2 88.2±0.3 89.6±0.4

_U →_ _M_ 82.1±0.7 84.9±1.3 85.3±0.6 86.7±1.5 87.4±0.8 87.9±0.7 89.8±0.4
Average of 4 tasks 65.6±0.7 68.7±1.0 70.4±0.7 72.4±0.9 73.3±0.7 74.1±0.8 75.6±0.8


TOHAN

DEG-Net


_M →_ _U_ 76.0±1.9 83.3±0.3 84.2±0.4 86.5±1.1 87.1±1.3 88.0±0.5 89.7±0.5
_M →_ _S_ 26.7±0.1 28.6±1.1 29.5±1.4 29.6±0.4 30.5±1.2 32.1±0.2 33.2±0.8
_S →_ _M_ 76.0±1.9 83.3±0.3 84.2±0.4 86.5±1.1 87.1±1.3 88.0±0.5 89.7±0.5
_U →_ _M_ 84.0±0.5 85.2±0.3 85.6±0.7 86.5±0.5 87.3±0.6 88.2±0.7 89.2±0.5
Average of 4 tasks 65.7±1.1 **70.1±0.5** 70.9±0.7 72.2±0.8 73.0±1.1 74.0±0.5 75.5±0.6

_M →_ _U_ 83.1±0.9 86.2±0.8 86.5±0.6 88.7±0.9 89.6±0.5 91.5±0.6 92.1±0.6
_M →_ _S_ 27.2±0.3 28.5±1.3 29.7±0.9 30.7±0.8 32.9±1.5 33.7±1.8 34.9±1.6
_S →_ _M_ 76.2±1.3 78.2±1.3 85.7±0.6 85.9±0.8 88.6±1.6 89.5±1.2 90.2±0.7
_U →_ _M_ 82.2±0.7 85.9±0.6 86.5±1.5 87.8±0.9 88.9±0.9 90.3±0.5 91.6±1.2
Average of 4 tasks **67.1±0.8** 69.7±1.0 **72.1±0.9** **73.3±0.9** **75.0±1.1** **76.3±1.0** **77.2±1.0**


Table 5: The Diversity of the target data and generated data by different methods.

Task Target Data TOHAN DEG-Net

_M →_ _S_ 0.0027 **0.0019**
_U →_ _S_ 0.0013 0.0025 **0.0021**

_S →_ _M_ 0.0016 **0.0013**
_U →_ _M_ 0.0004 0.0014 **0.0008**

_S →_ _U_ 0.0012 **0.001**
0.0002
_M →_ _U_ 0.0009 **0.0005**

update classifier ft:

_L[∗]f_ [=][ −] _[γ][E][ˆ][ [][y]G1_ [log (][D][ (][ϕ][ (][G]2[)))][ −] _[y]G3_ [log (][D][ (][ϕ][ (][G]4[)))]]

(23)
+ E[ˆ] [ℓ (ft (xt)), ft[∗] [(][X][t][))] + ˆ][E][ [][ℓ] [(][f][t] [(][x][g][))][, f][ ∗]t [(][x][g][))]][,]

where xg is the generated data and ft[∗][(][x][g][)][ is the label of the generated data. We use the different]
numbers of the generated data by TOHAN (Chi et al., 2021a) and DEG-Net to train the classifier
and the classification accuracy is shown in Table 6. It is clear that the performance of using data
generated by TOHAN is almost the same as just using labeled data. In addition, the data generated by
DEG-Net can not improve the performance of the model while the number of the target data per class
is small . It may be caused by that the generated data is similar to the label target data, so that add the
almost same data for the training will bring little improvement. However, it is worth nothing that the
improvement will be large if the number of data generated by DEG-Net is more than 5 per class. This
phenomenon indicates that that the data generated by DEG-Net is more independent to the existing
target data and could be treated as the new ones in some degree.


-----

Table 6: Classification accuracy (%) on digits FHA tasks using the generated data. Bold value
represents the highest average accuracy on each column

Number of Target Data per Class
Task Method Number of Generated Data per Class 1 2 3 4 5 6 7


0 **76.0** 83.3 84.2 **86.5** **87.1** **88.0** **89.7**
5 75.8 **83.7** **84.3** 84.3 85.0 87.5 88.1
20 76.0 83.3 84.3 84.0 85.1 87.2 89.5

0 **83.1** **86.2** **86.5** **88.7** 89.6 91.5 92.1
5 82.6 86.0 85.9 88.2 88.7 91.9 92.3
20 81.3 84.3 86.2 88.6 **90.3** **92.3** **93.4**

0 **26.7** **28.6** 29.5 **29.6** **30.5** 32.1 **33.2**
5 26.2 28.4 28.9 29.1 30.2 31.4 32.5
20 25.8 26.9 29.8 27.4 29.8 **32.7** 32.8

0 27.2 **28.5** 29.7 **30.7** 32.9 33.7 34.9
5 **27.3** 28.2 29.6 29.4 32.8 33.8 35.4
20 26.4 27.3 **30.2** 28.9 **33.5** **35.0** **36.4**


_M →_ _U_

_M →_ _S_


TOHAN

DEG-Net

TOHAN

DEG-Net


-----

